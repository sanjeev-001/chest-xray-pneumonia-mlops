# Prometheus Configuration for Production MLOps Monitoring

# Global Prometheus configuration
prometheus:
  prometheusSpec:
    # Resource allocation
    resources:
      requests:
        memory: "2Gi"
        cpu: "1000m"
      limits:
        memory: "4Gi"
        cpu: "2000m"
    
    # Storage configuration
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
    
    # Retention policy
    retention: 30d
    retentionSize: 45GB
    
    # Security context
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
      fsGroup: 65534
    
    # Pod disruption budget
    podDisruptionBudget:
      enabled: true
      minAvailable: 1
    
    # Service monitor selector
    serviceMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}
    serviceMonitorNamespaceSelector: {}
    
    # Rule selector
    ruleSelectorNilUsesHelmValues: false
    ruleSelector: {}
    ruleNamespaceSelector: {}
    
    # Additional scrape configs for MLOps components
    additionalScrapeConfigs:
    - job_name: 'mlops-model-server'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - production-blue
          - production-green
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: model-server
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: metrics
    
    - job_name: 'mlops-data-pipeline'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - production-blue
          - production-green
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: data-pipeline
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: metrics
    
    - job_name: 'mlops-training-service'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - production-blue
          - production-green
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: training-service
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: metrics

# Alertmanager configuration
alertmanager:
  alertmanagerSpec:
    # Resource allocation
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "200m"
    
    # Storage configuration
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
    
    # Security context
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
      fsGroup: 65534
    
    # Configuration
    config:
      global:
        smtp_smarthost: 'localhost:587'
        smtp_from: 'alertmanager@mlops.example.com'
        smtp_auth_username: 'alertmanager@mlops.example.com'
        smtp_auth_password: 'password'
      
      route:
        group_by: ['alertname', 'cluster', 'service']
        group_wait: 10s
        group_interval: 10s
        repeat_interval: 1h
        receiver: 'web.hook'
        routes:
        - match:
            severity: critical
          receiver: 'critical-alerts'
        - match:
            severity: warning
          receiver: 'warning-alerts'
      
      receivers:
      - name: 'web.hook'
        webhook_configs:
        - url: 'http://webhook-service:5000/alerts'
      
      - name: 'critical-alerts'
        email_configs:
        - to: 'oncall@mlops.example.com'
          subject: 'CRITICAL: {{ .GroupLabels.alertname }}'
          body: |
            {{ range .Alerts }}
            Alert: {{ .Annotations.summary }}
            Description: {{ .Annotations.description }}
            {{ end }}
        slack_configs:
        - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
          channel: '#alerts-critical'
          title: 'CRITICAL Alert'
          text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
      
      - name: 'warning-alerts'
        email_configs:
        - to: 'team@mlops.example.com'
          subject: 'WARNING: {{ .GroupLabels.alertname }}'
          body: |
            {{ range .Alerts }}
            Alert: {{ .Annotations.summary }}
            Description: {{ .Annotations.description }}
            {{ end }}

# Grafana configuration
grafana:
  enabled: true
  
  # Admin credentials
  adminPassword: "admin123"  # Change this in production
  
  # Resource allocation
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "200m"
  
  # Persistence
  persistence:
    enabled: true
    storageClassName: gp3
    size: 10Gi
  
  # Security context
  securityContext:
    runAsNonRoot: true
    runAsUser: 472
    fsGroup: 472
  
  # Service configuration
  service:
    type: ClusterIP
    port: 80
  
  # Ingress configuration
  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      cert-manager.io/cluster-issuer: "letsencrypt-prod"
    hosts:
    - grafana.mlops.example.com
    tls:
    - secretName: grafana-tls
      hosts:
      - grafana.mlops.example.com
  
  # Data sources
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        url: http://prometheus-kube-prometheus-prometheus:9090
        access: proxy
        isDefault: true
  
  # Dashboard providers
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default
  
  # Pre-configured dashboards
  dashboards:
    default:
      # Kubernetes cluster overview
      kubernetes-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
      
      # Node exporter dashboard
      node-exporter:
        gnetId: 1860
        revision: 27
        datasource: Prometheus
      
      # MLOps model performance dashboard
      mlops-model-performance:
        json: |
          {
            "dashboard": {
              "id": null,
              "title": "MLOps Model Performance",
              "tags": ["mlops", "model"],
              "timezone": "browser",
              "panels": [
                {
                  "id": 1,
                  "title": "Model Inference Rate",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "rate(model_inference_requests_total[5m])",
                      "legendFormat": "{{instance}}"
                    }
                  ]
                },
                {
                  "id": 2,
                  "title": "Model Accuracy",
                  "type": "stat",
                  "targets": [
                    {
                      "expr": "model_accuracy",
                      "legendFormat": "Accuracy"
                    }
                  ]
                },
                {
                  "id": 3,
                  "title": "Prediction Latency",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "histogram_quantile(0.95, rate(model_inference_duration_seconds_bucket[5m]))",
                      "legendFormat": "95th percentile"
                    }
                  ]
                }
              ],
              "time": {
                "from": "now-1h",
                "to": "now"
              },
              "refresh": "30s"
            }
          }

# Node exporter configuration
nodeExporter:
  enabled: true
  
# Kube state metrics configuration
kubeStateMetrics:
  enabled: true

# Service monitors for MLOps components
additionalServiceMonitors:
- name: mlops-model-server
  selector:
    matchLabels:
      app: model-server
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics

- name: mlops-data-pipeline
  selector:
    matchLabels:
      app: data-pipeline
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics

# Prometheus rules for MLOps alerts
additionalPrometheusRules:
- name: mlops-alerts
  groups:
  - name: model-performance
    rules:
    - alert: ModelAccuracyLow
      expr: model_accuracy < 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Model accuracy is below threshold"
        description: "Model accuracy has been below 80% for more than 5 minutes"
    
    - alert: ModelInferenceLatencyHigh
      expr: histogram_quantile(0.95, rate(model_inference_duration_seconds_bucket[5m])) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Model inference latency is high"
        description: "95th percentile latency is above 2 seconds"
    
    - alert: ModelServerDown
      expr: up{job="mlops-model-server"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Model server is down"
        description: "Model server has been down for more than 1 minute"
  
  - name: data-pipeline
    rules:
    - alert: DataPipelineFailure
      expr: increase(data_pipeline_errors_total[5m]) > 5
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "Data pipeline errors detected"
        description: "More than 5 data pipeline errors in the last 5 minutes"
    
    - alert: DataQualityIssue
      expr: data_quality_score < 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Data quality score is low"
        description: "Data quality score has been below 90% for more than 5 minutes"